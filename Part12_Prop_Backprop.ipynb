{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 12: Prop, Backprop\n",
    "Let's review.\n",
    "\n",
    "We saw that an untrained network predicts about 50% for everything, since it has seen no examples. Then we gave it a few examples and it learned a little bit. Then we gave it more, and it learned more.\n",
    "\n",
    "Then it got stuck, and we used some tricks to perturb the few samples we had to make a lot more, and suddenly the learning got better and with fewer epochs.\n",
    "\n",
    "Then we gave it more colors and even more, and it worked pretty well. We had so many perturbed color samples that we were able to keep some examples to test against and see if the network was doing a good job of learning more than just what it was given. It did.\n",
    "\n",
    "But how did it work? How was it able to learn at all with all those examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give Me Some Bias\n",
    "A plain-vanilla untrained network has some small numbers for its biases and weights, but really you can think of it as a blank slate. What our training does is provide feedback to the network to tell it to make itself better. We give it an example by setting the R, G, B sensors to the values of a color like gray, (0.5, 0.5, 0.5), then letting the network run the math forward through the network. This is *forward propagation*. The RGB values are received at the middle layer perceptrons, multiplied by the weights, added together, and if the value is big enough, the perceptrons get triggered and pass on a value to the output perceptrons. (Remember, this is just like the the perceptrons we played with in lesson 8 - they add their inputs and maybe become triggered.) Those perceptrons have weights of their own, multiplying the inputs from the middle layer, adding the results together, and we get the predictions as floating point numbers, where the number is between zero and 1 and is the network's decision about the probabilty of each of the colors being a match for the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ColorMatchingNetDiagram.png](./ColorMatchingNetDiagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Mistake, Walk It Back\n",
    "We kind of knew all that already. And when we get the resulting outputs, they start out right around 50% for each of the colors, which means uncertain. But how do we tell the network to get better?\n",
    "\n",
    "This is where *backpropagation* comes in. Just as we stepped *forward* through the network, starting at the incoming color values and applying our perceptron math operations at each step, so we compare the result against what we wanted (this is called the *error*), walk *back* to each perceptron in the middle layer and adjust the biases and weights to get it closer to calculating the right result. This adjustment is called *backpropagation*. So that during the next epoch the weights and biases produce a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch It\n",
    "When our batch size hyperparameter is 1, we do all of this work for each color sample: We show the color sample to the RGB sensors, run the math forward through the network, find how far away from the right color prediction the network was, then *backpropagate* through the network, adjusting things a bit, and on and on. And then do it all again for the next epoch, and again and again.\n",
    "\n",
    "When the batch size is more than 1, we run several samples through in the forward direction, tracking the error for each one, then run backpropagation once to get the weights closer for all of the samples at once. This is why a bigger batch size makes for less accurate training - we are combining the adjustments for a single backpropagation, which blends the adjustments together, which is less precise than doing it each time. But backpropagation is expensive in terms of math, and we are impatient, so we try different batch sizes to see what takes less time but is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Me\n",
    "This is all fine, but it's better if we learn by seeing and doing, not just talking and thinking. Lets go back to the beginning and look at our earliest network, but this time let's take a look inside the math. Below we create a program that lets us look inside a small network, and we'll feed it three samples, black, gray, and white, and see what happens.\n",
    "\n",
    "Note that we're only animating a batch size of 1. And you will be manualy running the epochs by selecting which color to train on for each iteration.\n",
    "\n",
    "First, some helper code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import time, random\n",
    "\n",
    "def centerText(displayWidth, text, c=' '):\n",
    "    pre = (displayWidth - len(text)) // 2\n",
    "    post = displayWidth - len(text) - pre\n",
    "    return c * pre + text + c * post\n",
    "\n",
    "def formatArray(displayWidth, arr):\n",
    "    return centerText(displayWidth, \" \".join([ (\"% .2f\" % a) for a in arr ]))\n",
    "\n",
    "def red(text):\n",
    "    return \"\\033[31m\" + text + \"\\033[0m\"  # ANSI console color code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a Perceptron class so the code related to a perceptron is in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, numInputs, learningRate = 0.5):\n",
    "        self.bias = 0.0\n",
    "        self.weights = [random.gauss(0.0, 0.01) for i in range(numInputs)]\n",
    "        self.currentInputs = [0.0] * numInputs\n",
    "        self.learningRate = learningRate\n",
    "        self.sumOfWeightScaledInputs = 0.0\n",
    "        self.output = 0.0\n",
    "        self.triggered = False\n",
    "        self.printWidth = 5 * numInputs + (numInputs - 1)\n",
    "        self.error = 0.0\n",
    "    \n",
    "    def display(self, showInputs):\n",
    "        if showInputs:\n",
    "            print(self.getInputsDisplay())\n",
    "        print(self.getWeightsDisplay())\n",
    "        print(self.getBiasDisplay())\n",
    "\n",
    "    def getInputsDisplay(self):\n",
    "        return formatArray(self.printWidth, self.currentInputs)\n",
    "    \n",
    "    def getWeightsDisplay(self):\n",
    "        return formatArray(self.printWidth, self.weights)\n",
    "    \n",
    "    def getValueDisplay(self, value):\n",
    "        return centerText(self.printWidth, \"% .2f\" % value)\n",
    "        \n",
    "    def getBiasDisplay(self):\n",
    "        return self.getValueDisplay(self.bias)\n",
    "\n",
    "    def getBiasCheckDisplay(self):\n",
    "        return centerText(self.printWidth, \"% .2f > % .2f ?\" % (self.sumOfWeightScaledInputs, self.bias))\n",
    "\n",
    "    def getOutputDisplay(self):\n",
    "        return self.getValueDisplay(self.output)\n",
    "    \n",
    "    def acceptInputsCheckIfTriggered(self, inputs):\n",
    "        # inputs is an array of size numInputs.\n",
    "        self.currentInputs = inputs\n",
    "        self.sumOfWeightScaledInputs = 0\n",
    "        for i in range(len(inputs)):\n",
    "            self.sumOfWeightScaledInputs += inputs[i] * self.weights[i]\n",
    "        self.triggered = (self.sumOfWeightScaledInputs > self.bias)\n",
    "        if (self.triggered):\n",
    "            self.output = 1.0\n",
    "        else:\n",
    "            self.output = 0.0\n",
    "\n",
    "    def backPropagate(self, expectedOutput):\n",
    "        # expectedOutput is the value the next layer was expecting to see. If this\n",
    "        # is an output neuron, it's 1 if this neuron should have predicted the related\n",
    "        # item at 100%, or 0 if it should have predicted 0%. For a middle layer,\n",
    "        # it is the self.error * self.weight for each link back from a later layer to\n",
    "        # this perceptron.\n",
    "        self.error = (expectedOutput - self.output) * (expectedOutput - self.output)\n",
    "        self.bias += self.learningRate * (expectedOutput - self.bias)\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += self.learningRate * (expectedOutput - self.output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create a small network with 3 color inputs (red, green blue), 4 middle layer perceptrons, and 1 output perceptron for each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorMap = {\n",
    "    'white': (1.0, 1.0, 1.0),\n",
    "    'black': (0.0, 0.0, 0.0),\n",
    "    'gray': (0.5, 0.5, 0.5)\n",
    "}\n",
    "\n",
    "numMiddleLayerPerceptrons = 4\n",
    "middleLayer = [ Perceptron(3) for i in range(numMiddleLayerPerceptrons) ]\n",
    "outputLayer = [ Perceptron(numMiddleLayerPerceptrons) for i in range(len(colorMap))]\n",
    "displayWidth = max(numMiddleLayerPerceptrons, len(colorMap)) * (middleLayer[0].printWidth + 3)\n",
    "def getCentered(text, c=' '): return centerText(displayWidth, text, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That network looks like this:\n",
    "\n",
    "![ColorMatchingNetDiagram2.png](./ColorMatchingNetDiagram2.png)\n",
    "\n",
    "Finally let's create some code that will let us watch, at whatever speed we want, a color input propagate forward, then the error correction propagate backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def showMeTheNetwork(color=None, stepPauseSec=2.0):\n",
    "    global middleLayer, finalLayer\n",
    "    if color:\n",
    "        rgb = colorMap[color]\n",
    "        oneHotOutputArray = [0.0] * len(colorMap)\n",
    "        i = 0\n",
    "        for colorName in colorMap:\n",
    "            if colorName == color:\n",
    "                oneHotOutputArray[i] = 1.0\n",
    "                break\n",
    "            i += 1\n",
    "        print(\"rgb:     \" + getCentered(\" \".join([ (\"% .2f\" % c) for c in rgb ])))\n",
    "    else:\n",
    "        print()\n",
    "    print()\n",
    "    print(\"         \" + getCentered(\" middle layer \", '-'))\n",
    "    if color:\n",
    "        for p in middleLayer: p.currentInputs = rgb\n",
    "        print(\"inputs:  \" + getCentered(\" | \".join([ p.getInputsDisplay() for p in middleLayer ])))\n",
    "        time.sleep(stepPauseSec)\n",
    "    else:\n",
    "        print()\n",
    "    print(\"weights: \" + getCentered(\" | \".join([ p.getWeightsDisplay() for p in middleLayer ])))\n",
    "    if color:\n",
    "        time.sleep(stepPauseSec)\n",
    "        for p in middleLayer:\n",
    "            p.acceptInputsCheckIfTriggered(rgb)\n",
    "        print(\"trigger?  \" + \" | \".join([ p.getBiasCheckDisplay() for p in middleLayer ]))\n",
    "        time.sleep(stepPauseSec)\n",
    "    else:\n",
    "        print()\n",
    "    print(\"outputs:  \" + \" | \".join([ p.getOutputDisplay() for p in middleLayer ]))\n",
    "    print(\"         \" + getCentered(\"\", '-'))\n",
    "\n",
    "    print()\n",
    "    print(\"         \" + getCentered(\" output layer \", '-'))\n",
    "    if color:\n",
    "        middleLayerOutputs = []\n",
    "        for p in middleLayer: middleLayerOutputs.append(p.output)\n",
    "        for p in outputLayer: p.currentInputs = middleLayerOutputs\n",
    "        print(\"inputs:  \" + getCentered(\" | \".join([ p.getInputsDisplay() for p in outputLayer ])))\n",
    "        time.sleep(stepPauseSec)\n",
    "    else:\n",
    "        print()\n",
    "    print(\"weights: \" + getCentered(\" | \".join([ p.getWeightsDisplay() for p in outputLayer ])))\n",
    "    if color:\n",
    "        time.sleep(stepPauseSec)\n",
    "        for p in outputLayer:\n",
    "            p.acceptInputsCheckIfTriggered(middleLayerOutputs)\n",
    "        print(\"trigger?   \" + \" | \".join([ p.getBiasCheckDisplay() for p in outputLayer ]))\n",
    "        time.sleep(stepPauseSec)\n",
    "    else:\n",
    "        print()\n",
    "    print(\"outputs:   \" + \" | \".join([ p.getOutputDisplay() for p in outputLayer ]))\n",
    "    print(\"         \" + getCentered(\"\", '-'))\n",
    "\n",
    "    if color:\n",
    "        time.sleep(stepPauseSec)\n",
    "        print(\"expect:  \" + getCentered(\"   \".join([ outputLayer[0].getValueDisplay(c) for c in oneHotOutputArray ])))\n",
    "        time.sleep(stepPauseSec)\n",
    "        print()\n",
    "        print(\"         \" + getCentered(\"BACKPROPAGATE - New weights and biases:\"))\n",
    "        for i in range(len(outputLayer)):\n",
    "            outputLayer[i].backPropagate(oneHotOutputArray[i])\n",
    "        time.sleep(stepPauseSec)\n",
    "        print()\n",
    "        print(\"         \" + getCentered(\" output layer \", '-'))\n",
    "        print(\"weights: \" + getCentered(\" | \".join([ red(p.getWeightsDisplay()) for p in outputLayer ])))\n",
    "        print(\"bias:    \" + getCentered(\" | \".join([ red(p.getBiasDisplay()) for p in outputLayer ])))\n",
    "        \n",
    "        for i in range(len(middleLayer)):\n",
    "            expectedOutput = 0.0\n",
    "            for j in range(len(outputLayer)):\n",
    "                expectedOutput += outputLayer[j].weights[i] * outputLayer[j].error\n",
    "            expectedOutput /= float(len(outputLayer))\n",
    "            middleLayer[i].backPropagate(expectedOutput)\n",
    "        time.sleep(stepPauseSec)\n",
    "        print()\n",
    "        print(\"         \" + getCentered(\" middle layer \", '-'))\n",
    "        print(\"weights: \" + getCentered(\" | \".join([ red(p.getWeightsDisplay()) for p in middleLayer ])))\n",
    "        print(\"bias:    \" + getCentered(\" | \".join([ red(p.getBiasDisplay()) for p in middleLayer ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of controls below let you choose which color to train next, and watch the perceptrons propagate forward then backward. Use the dropdown list to select a color to train, and cycle through the colors several times to watch the weights change, particularly when there is a difference from the actual and expected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79304f9e0de54c1aa8d0319e147cabd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='color', options=('white', 'gray', 'black'), value=None), FloatSlid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.showMeTheNetwork(color=None, stepPauseSec=2.0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(showMeTheNetwork, color=['white', 'gray', 'black'], stepPauseSec=(0.0, 20.0, 0.5, 3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coming up...\n",
    "We'll use the largest crayon box we can, and finish things up... for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
