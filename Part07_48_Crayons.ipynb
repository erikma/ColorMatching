{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: 48 Crayons\n",
    "Let's review where we've been so far:\n",
    "\n",
    "* We got a basic neural network up and running and trained it to predict the name of a few colors.\n",
    "* We added more colors until we ran into problems with the training taking too many repetitions, *epochs*, and not getting much better after awhile.\n",
    "* So we *perturbed* our data, wiggling the color values around a little bit and calling the new values the same color as the original. This gave the network lots more examples - which networks typically like a lot! - and helped us converge to a lower loss in only a few epochs, but at the cost of each epoch taking a lot of time.\n",
    "\n",
    "We've not discussed exactly what the network does inside. That's a lot of detail that we will start to get into soon.\n",
    "\n",
    "In the meantime, as promised last time, it's time to try doubling our crayon colors from 24 to 48. Let's give it a go and see where things end up.\n",
    "\n",
    "Hint: There are two new changes in this code from last time. See if you can spot them; we'll use them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "import keras.optimizers, keras.utils, numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def train(rgbValues, colorNames, epochs = 16, perceptronsPerColorName = 8, batchSize = 1):\n",
    "    \"\"\"\n",
    "    Trains a neural network to understand how to map color names to RGB triples.\n",
    "    The provided lists of RGB triples must be floating point triples with each\n",
    "    value in the range [0.0, 1.0], and the number of color names must be the same length.\n",
    "    Different names are allowed to map to the same RGB triple.\n",
    "    Returns a trained model that can be used for recognize().\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the Python map RGB values into a numpy array needed for training.\n",
    "    rgbNumpyArray = numpy.array(rgbValues, numpy.float64)\n",
    "    \n",
    "    # Convert the color labels into a one-hot feature array.\n",
    "    # Text labels for each array position are in the classes_ list on the binarizer.\n",
    "    labelBinarizer = LabelBinarizer()\n",
    "    oneHotLabels = labelBinarizer.fit_transform(colorNames)\n",
    "    numColors = len(labelBinarizer.classes_)\n",
    "    colorLabels = labelBinarizer.classes_\n",
    "    \n",
    "    # Hyperparameters to define the network shape.\n",
    "    numFullyConnectedPerceptrons = numColors * perceptronsPerColorName\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Layer 1: Fully connected layer with ReLU activation.\n",
    "        Dense(numFullyConnectedPerceptrons, activation='relu', kernel_initializer='TruncatedNormal', input_shape=(3,)),\n",
    "\n",
    "        # Outputs: SoftMax activation to get probabilities by color.\n",
    "        Dense(numColors, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # Compile for categorization.\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.SGD(lr = 0.01, momentum = 0.9, decay = 1e-6, nesterov = True),\n",
    "        loss = 'categorical_crossentropy',\n",
    "        metrics = [ 'accuracy' ])\n",
    "\n",
    "    history = model.fit(rgbNumpyArray, oneHotLabels, epochs=epochs, batch_size=batchSize)\n",
    "\n",
    "    return (model, colorLabels)\n",
    "\n",
    "def createMoreTrainingData(colorNameToRGBMap):\n",
    "    # The incoming color map is not typically going to be oversubscribed with e.g.\n",
    "    # extra 'red' samples pointing to slightly different colors. We generate a\n",
    "    # training dataset by perturbing each color by a small amount positive and\n",
    "    # negative. We do this for each color individually, by pairs, and for all three\n",
    "    # at once, for each positive and negative value, resulting in dataset that is\n",
    "    # many times as large.\n",
    "    perturbValues = [ 0.0, 0.01, 0.02, 0.03 ] # TODO: Experiment with adding 0.04, 0.05\n",
    "    rgbValues = []\n",
    "    labels = []\n",
    "    for colorName, rgb in colorNameToRGBMap.items():\n",
    "        reds = []\n",
    "        greens = []\n",
    "        blues = []\n",
    "        for perturb in perturbValues:\n",
    "            if rgb[0] + perturb <= 1.0:\n",
    "                reds.append(rgb[0] + perturb)\n",
    "            if perturb != 0.0 and rgb[0] - perturb >= 0.0:\n",
    "                reds.append(rgb[0] - perturb)\n",
    "            if rgb[1] + perturb <= 1.0:\n",
    "                greens.append(rgb[1] + perturb)\n",
    "            if perturb != 0.0 and rgb[1] - perturb >= 0.0:\n",
    "                greens.append(rgb[1] - perturb)\n",
    "            if rgb[2] + perturb <= 1.0:\n",
    "                blues.append(rgb[2] + perturb)\n",
    "            if perturb != 0.0 and rgb[2] - perturb >= 0.0:\n",
    "                blues.append(rgb[2] - perturb)\n",
    "        for red in reds:\n",
    "            for green in greens:\n",
    "                for blue in blues:\n",
    "                    rgbValues.append((red, green, blue))\n",
    "                    labels.append(colorName)\n",
    "    return (rgbValues, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then our newly expanded color list, and training a small number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 384)               1536      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 48)                18480     \n",
      "=================================================================\n",
      "Total params: 20,016\n",
      "Trainable params: 20,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "14553/14553 [==============================] - 27s 2ms/step - loss: 1.2467 - acc: 0.6116\n",
      "Epoch 2/5\n",
      "14553/14553 [==============================] - 20s 1ms/step - loss: 0.5498 - acc: 0.8172\n",
      "Epoch 3/5\n",
      "14553/14553 [==============================] - 24s 2ms/step - loss: 0.4497 - acc: 0.8516\n",
      "Epoch 4/5\n",
      "14553/14553 [==============================] - 27s 2ms/step - loss: 0.4180 - acc: 0.8634\n",
      "Epoch 5/5\n",
      "14553/14553 [==============================] - 29s 2ms/step - loss: 0.3717 - acc: 0.8762\n"
     ]
    }
   ],
   "source": [
    "def rgbToFloat(r, g, b):  # r, g, b in 0-255 range\n",
    "    return (float(r) / 255.0, float(g) / 255.0, float(b) / 255.0)\n",
    "\n",
    "# http://www.jennyscrayoncollection.com/2017/10/complete-list-of-current-crayola-crayon.html\n",
    "colorMap = {\n",
    "    # 8-crayon box colors\n",
    "    'red': rgbToFloat(238, 32, 77),\n",
    "    'yellow': rgbToFloat(252, 232, 131),\n",
    "    'blue': rgbToFloat(31, 117, 254),\n",
    "    'brown': rgbToFloat(180, 103, 77),\n",
    "    'orange': rgbToFloat(255, 117, 56),\n",
    "    'green': rgbToFloat(28, 172, 20),\n",
    "    'violet': rgbToFloat(146, 110, 174),\n",
    "    'black': rgbToFloat(35, 35, 35),\n",
    "\n",
    "    # Additional for 16-count box\n",
    "    'red-violet': rgbToFloat(192, 68, 143),\n",
    "    'red-orange': rgbToFloat(255, 117, 56),\n",
    "    'yellow-green': rgbToFloat(197, 227, 132),\n",
    "    'blue-violet': rgbToFloat(115, 102, 189),\n",
    "    'carnation-pink': rgbToFloat(255, 170, 204),\n",
    "    'yellow-orange': rgbToFloat(255, 182, 83),\n",
    "    'blue-green': rgbToFloat(25, 158, 189),\n",
    "    'white': rgbToFloat(237, 237, 237),\n",
    "\n",
    "    # Additional for 24-count box\n",
    "    'violet-red': rgbToFloat(247, 83 ,148),\n",
    "    'apricot': rgbToFloat(253, 217, 181),\n",
    "    'cerulean': rgbToFloat(29, 172, 214),\n",
    "    'indigo': rgbToFloat(93, 118, 203),\n",
    "    'scarlet': rgbToFloat(242, 40, 71),\n",
    "    'green-yellow': rgbToFloat(240, 232, 145),\n",
    "    'bluetiful': rgbToFloat(46, 80, 144),\n",
    "    'gray': rgbToFloat(149, 145, 140),\n",
    "    \n",
    "    # Additional for 32-count box\n",
    "    'chestnut': rgbToFloat(188, 93, 88),\n",
    "    'peach': rgbToFloat(255, 207, 171),\n",
    "    'sky-blue': rgbToFloat(128, 215, 235),\n",
    "    'cadet-blue': rgbToFloat(176, 183, 198),\n",
    "    'melon': rgbToFloat(253, 188, 180),\n",
    "    'tan': rgbToFloat(250, 167, 108),\n",
    "    'wisteria': rgbToFloat(205, 164, 222),\n",
    "    'timberwolf': rgbToFloat(219, 215, 210),\n",
    "\n",
    "    # Additional for 48-count box\n",
    "    'lavender': rgbToFloat(252, 180, 213),\n",
    "    'burnt-sienna': rgbToFloat(234, 126, 93),\n",
    "    'olive-green': rgbToFloat(186, 184, 108),\n",
    "    'purple-mountains-majesty': rgbToFloat(157, 129, 186),\n",
    "    'salmon': rgbToFloat(255, 155, 170),\n",
    "    'macaroni-and-cheese': rgbToFloat(255, 189, 136),\n",
    "    'granny-smith-apple': rgbToFloat(168, 228, 160),\n",
    "    'sepia': rgbToFloat(165, 105, 79),\n",
    "    'mauvelous': rgbToFloat(239, 152, 170),\n",
    "    'goldenrod': rgbToFloat(255, 217, 117),\n",
    "    'sea-green': rgbToFloat(159, 226, 191),\n",
    "    'raw-sienna': rgbToFloat(214, 138, 89),\n",
    "    'mahogany': rgbToFloat(205, 74, 74),\n",
    "    'spring-green': rgbToFloat(236, 234, 190),\n",
    "    'cornflower': rgbToFloat(154, 206, 235),\n",
    "    'tumbleweed': rgbToFloat(222, 170, 136),\n",
    "}\n",
    "\n",
    "(rgbValues, colorNames) = createMoreTrainingData(colorMap)\n",
    "(colorModel, colorLabels) = train(rgbValues, colorNames, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 3 epochs my machine went from 1.2 down to 0.43, then by 5 epochs it got down to 0.37. Plus note it takes longer since we have more colors, more added perturbed colors, and the network itself needs to be bigger to handle more colors.\n",
    "\n",
    "Let's see how it performs by testing with the sliders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56a40f528f64909b3050fa0b825ba67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='r', max=1.0, step=0.01), FloatSlider(value=0.5, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def displayColor(r, g, b):\n",
    "    rInt = min(255, max(0, int(r * 255.0)))\n",
    "    gInt = min(255, max(0, int(g * 255.0)))\n",
    "    bInt = min(255, max(0, int(b * 255.0)))\n",
    "    hexColor = \"#%02X%02X%02X\" % (rInt, gInt, bInt)\n",
    "    display(HTML('<div style=\"width: 50%; height: 50px; background: ' + hexColor + ';\"></div>'))\n",
    "\n",
    "numPredictionsToShow = 5\n",
    "@interact(r = (0.0, 1.0, 0.01), g = (0.0, 1.0, 0.01), b = (0.0, 1.0, 0.01))\n",
    "def getTopPredictionsFromModel(r, g, b):\n",
    "    testColor = numpy.array([ (r, g, b) ])\n",
    "    predictions = colorModel.predict(testColor, verbose=0)  # Predictions shape (1, numColors)\n",
    "    predictions *= 100.0\n",
    "    predColorTuples = []\n",
    "    for i in range(0, len(colorLabels)):\n",
    "        predColorTuples.append((predictions[0][i], colorLabels[i]))\n",
    "    predAndNames = numpy.array(predColorTuples, dtype=[('pred', float), ('colorName', 'U50')])\n",
    "    sorted = numpy.sort(predAndNames, order=['pred', 'colorName'])\n",
    "    sorted = sorted[::-1]  # reverse rows to get highest on top\n",
    "    for i in range(0, numPredictionsToShow):\n",
    "        print(\"%2.1f\" % sorted[i][0] + \"%\", sorted[i][1])\n",
    "    displayColor(r, g, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather good results! With so many more colors to choose from, the network is predicting rather well the in-between colors.\n",
    "\n",
    "And of course, next is the slider that lets you play around with the epochs. But this time there are new sliders you can play with:\n",
    "\n",
    "* How many perceptrons - the elements that make up our network, which we'll describe more later on - are added for each color name. More perceptrons do not always mean more accuracy. And each perceptron we add increases the amount of math needed to train and use the network.\n",
    "* The batch size. This is how many color examples are given at a time before the network is told to adjust itself to the new data (which is called *backpropagation*, something we'll be learning more about later). We've been running with a batch size of 1 so far, which is slow but best for accuracy, whereas bigger numbers train faster but tend to be less accurate, meaning you might have to increase the epochs as well. Try running with batch sizes 3 and 5 and see if your results with the predicted colors are very different.\n",
    "\n",
    "Play with the numbers and see the results to get a feel for things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4bcaba491549fe8d87e5fbe0a6251a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='epochs', max=10, min=1), IntSlider(value=8, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(epochs = (1, 10), perceptronsPerColorName = (1, 32), batchSize = (1, 10))\n",
    "def trainModel(epochs=3, perceptronsPerColorName=8, batchSize=1):\n",
    "    global colorModel\n",
    "    global colorLabels\n",
    "    (colorModel, colorLabels) = train(rgbValues, colorNames, epochs=epochs, perceptronsPerColorName=perceptronsPerColorName, batchSize=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcb8a663d9d4fd7a7ba3cf2e76c33a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='r', max=1.0, step=0.01), FloatSlider(value=0.5, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.getTopPredictionsFromModel(r, g, b)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(getTopPredictionsFromModel, r = (0.0, 1.0, 0.01), g = (0.0, 1.0, 0.01), b = (0.0, 1.0, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What I found was that 2 and 3 perceptrons per color name were too low, the predictions were pretty bad at 3 epochs. At 4 it gets about as good as when it was at 8, and setting it to 28 did not much better at all.\n",
    "\n",
    "Similarly, batch size 2 seemed about as good as 1, but trained twice as fast, 3 a little bit less accurate but faster, but by 10 or so it was relatively inaccurate - loss of 0.86 instead of 0.4 - but had a lot faster training.\n",
    "\n",
    "Numbers like epochs, perceptron counts, and batch sizes are called *hyperparameters* to the neural network. Adjusting them can make the network better or worse at its job, and in fact for a given problem and set of training data there is not always an exact right set of numbers, instead you often have to run many experiments with different hyperparameters to try to find the best results.\n",
    "\n",
    "And if you have a lot of experiments, a lot of data, and a lot of perceptrons, you get even more math...\n",
    "\n",
    "### Coming up...\n",
    "We'll start using the hyperparameters to save a bit of training time at the cost of some accuracy. And we'll learn why perceptrons get *triggered*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
